{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJ84bqWPCYm"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1w5n0W02uiH"
      },
      "source": [
        "# Unsupervised learning with Autoencoder\n",
        "\n",
        "We first play with MNIST dataset and pieces of code seen during the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFac0UPC2uiI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7XyL-JX2uiM"
      },
      "source": [
        "## Loading MNIST\n",
        "\n",
        "MNIST is a dataset made of 60,000 images of handwritten digits (0 to 9) of size $28\\times 28$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yAsJijZ2uiM"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6koHB8Z_2uiQ"
      },
      "outputs": [],
      "source": [
        "# to be modified if not on colab\n",
        "ROOT_DIR = Path.home()\n",
        "root_dir = os.path.join(ROOT_DIR,'data/MNIST/')\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root_dir, train=True, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size=256, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root_dir, train=False, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1M2kLzn2uiT"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wugVCUrI2uiT"
      },
      "outputs": [],
      "source": [
        "def to_img(x):\n",
        "    x = x.cpu().data.numpy()\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = np.clip(x, 0, 1)\n",
        "    x = x.reshape([-1, 28, 28])\n",
        "    return x\n",
        "\n",
        "def plot_reconstructions(model):\n",
        "    \"\"\"\n",
        "    Plot 10 reconstructions from the test set. The top row is the original\n",
        "    digits, the bottom is the decoder reconstruction.\n",
        "    The middle row is the encoded vector.\n",
        "    The encoder is called by model.encoder\n",
        "    The decoder is called by model.decoder\n",
        "    \"\"\"\n",
        "    # encode then decode\n",
        "    data, _ = next(iter(test_loader))\n",
        "    data = data.view([-1, 784])\n",
        "    data.requires_grad = False\n",
        "    data = data.to(device)\n",
        "    true_imgs = data\n",
        "    encoded_imgs = model.encoder(data)\n",
        "    decoded_imgs = model.decoder(encoded_imgs)\n",
        "\n",
        "    true_imgs = to_img(true_imgs)\n",
        "    decoded_imgs = to_img(decoded_imgs)\n",
        "    encoded_imgs = encoded_imgs.cpu().data.numpy()\n",
        "\n",
        "    n = 10\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(3, n, i + 1)\n",
        "        plt.imshow(true_imgs[i])\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(3, n, i + 1 + n)\n",
        "        plt.imshow(encoded_imgs[i].reshape(-1,4))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(3, n, i + 1 + n + n)\n",
        "        plt.imshow(decoded_imgs[i])\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise some images\n",
        "data, _ = next(iter(train_loader))\n",
        "data = data.view([-1, 28, 28])\n",
        "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "      ax[i][j].imshow(data[i+j])\n",
        "      ax[i][j].get_xaxis().set_visible(False)\n",
        "      ax[i][j].get_yaxis().set_visible(False)\n",
        "      plt.gray()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ClPnEQljPYpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRAI3MaO2uiW"
      },
      "source": [
        "## Simple Auto-Encoder\n",
        "\n",
        "We'll start with the simplest autoencoder: a single, fully-connected layer as the encoder and decoder.\n",
        "\n",
        "1. Implement this network. Give the number of parameters and check it numerically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GApDwy6e2uiW"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        # Your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Your code here\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What should be the size of the input dimension? How about the encoding dimension?"
      ],
      "metadata": {
        "id": "PhHRTS2NPteM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. We'll be using [Adam optimizer](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam). Remind how SGD works, and the main features of Adam. What is the default learning rate?"
      ],
      "metadata": {
        "id": "qXiIMsWiP-MD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUbMKILV2uiZ"
      },
      "outputs": [],
      "source": [
        "input_dim = # What is the input dimension?\n",
        "encoding_dim = # How should the embedding one be?\n",
        "\n",
        "\n",
        "# Your code to create an instance of a model and define an optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Let us start with a simple loss: the $L_2$ norm between true and reconstructed images. Implement it using [torch documentation](https://pytorch.org/docs/stable/nn.html)."
      ],
      "metadata": {
        "id": "giobTUGgQRqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code to define a loss function"
      ],
      "metadata": {
        "id": "Dw3X-dhHQZ9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Fill in the following function allowing to train the model."
      ],
      "metadata": {
        "id": "dOmKBhqsQrB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3Zh8eQ_2uid"
      },
      "outputs": [],
      "source": [
        "def train_model(model,loss_fn,data_loader=None,epochs=1,optimizer=None):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            data = data.view([-1, 784]).to(device)\n",
        "\n",
        "\n",
        "            # Your code to optimize the network\n",
        "\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(data_loader.dataset),\n",
        "                    100. * batch_idx / len(data_loader), loss.data.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train the model for 10 epochs. Comment on the evolution of the loss."
      ],
      "metadata": {
        "id": "JbZTgvG9Q74z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dybe6kLJ2uig",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Your code to train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Plot the reconstruction on some test images using the  ``` plot_reconstructions ``` function. Comment. What are the flaws of the model, and what can we improve?"
      ],
      "metadata": {
        "id": "uj0yOLAmRK58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOPJgAUh2uij"
      },
      "outputs": [],
      "source": [
        "plot_reconstructions(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhCiHP7P2uil"
      },
      "source": [
        "## 1. Stacked Autoencoder\n",
        "\n",
        "Now you will code an autoencoder where both the encoder and the decoder are multilayer perceptron (MLP). You can take for the encoder a first hidden layer with dimension 128, a second one with dimension 64 and then the code of dimension 32. For the decoder, you can take the same sequence of dimensions in reverse order.\n",
        "\n",
        "8. First, draw a quick diagram of this network and implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrTmxg7z2uim"
      },
      "outputs": [],
      "source": [
        "class DeepAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super(DeepAutoEncoder, self).__init__()\n",
        "        #\n",
        "        # your code here\n",
        "        #\n",
        "\n",
        "    def forward(self, x):\n",
        "        #\n",
        "        # your code here\n",
        "        #\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Train your new model as done before and plot some the reconstruction. Is it working better visually?"
      ],
      "metadata": {
        "id": "IwdzTtqlR5FT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm_n3sI92uiq"
      },
      "outputs": [],
      "source": [
        "# Your code to train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_reconstructions(model)"
      ],
      "metadata": {
        "id": "2_M_2jFGWawr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIWLi9Ps2uix"
      },
      "source": [
        "10. Replace the `MSELoss` with a `BCEWithLogitsLoss` for each pixel. Note the unusual use of `BCEWithLogitsLoss`! You can have a look at the definition of [Cross Entropy](https://en.wikipedia.org/wiki/Cross_entropy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-eLv64aPCYw"
      },
      "outputs": [],
      "source": [
        "# Your code to create a new instance and change the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_depugxPCYw"
      },
      "outputs": [],
      "source": [
        "plot_reconstructions(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S8qgLsO2uix"
      },
      "source": [
        "## 2. Optional\n",
        "\n",
        "At this stage, you can code the interpolation described in the lesson to obtain:\n",
        "\n",
        "![](https://raw.githubusercontent.com/dataflowr/slides/master/images/module9/interp_AE.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3sm7Pi62ujU"
      },
      "source": [
        "# 3. Implement a denoising AE:\n",
        "\n",
        "\n",
        "11. Use the previous code and implement minimal modifications to tranform the AE into a denoising AE. First apply some noise to your input and try to recover the original data at the output. For the noise, you can add some random noise or erase some of the pixels. In this last case, you should obtain something like:\n",
        "![](https://raw.githubusercontent.com/dataflowr/slides/master/images/module9/denoising_AE.png)\n",
        "The first line corresponds to the original digit, the second line to the noisy version of the digit given as input to your network, the third line is the associated code and the last line is the denoised digit obtained by your decoder from the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isYFcQFS2ujU"
      },
      "outputs": [],
      "source": [
        "# You need first to modify the training process by adding noise to your data\n",
        "# Hint if you want to erase pixels: https://stackoverflow.com/questions/49216615/is-there-an-efficient-way-to-create-a-random-bit-mask-in-pytorch\n",
        "def train_denoiser(model,loss_fn,data_loader=None,epochs=1,optimizer=None, noise=0.1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            # Your code to noise the data\n",
        "\n",
        "            data = data.view([-1, 784]).to(device)\n",
        "            # Your code to train the network\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(data_loader.dataset),\n",
        "                100. * batch_idx / len(data_loader), loss.data.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBkQbfVl2ujX"
      },
      "outputs": [],
      "source": [
        "# Your code to create a new instance, define the loss and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGixZVJF2ujW"
      },
      "outputs": [],
      "source": [
        "# Now you need to modify the plot function\n",
        "def plot_denoising(model, noise=0.1):\n",
        "    \"\"\"\n",
        "    Plot 10 reconstructions from the test set. The top row is the original\n",
        "    digits, , the second row is the noisy digits,\n",
        "    the third row is the encoded vector and\n",
        "    the bottom is the decoder reconstruction.\n",
        "    \"\"\"\n",
        "    # encode then decode\n",
        "    data, _ = next(iter(test_loader))\n",
        "    #\n",
        "    # your code here to compute\n",
        "    # noisy_data\n",
        "    # encoded_imgs\n",
        "    # decoded_imgs\n",
        "    mask = torch.empty_like(data).uniform_() > noise\n",
        "    noisy_data = mask * data\n",
        "    # mask = torch.zeros_like(data)\n",
        "    # level = 10\n",
        "    # mask[:,:,-level:,:] = torch.ones(10,1,level,28)\n",
        "    # noisy_data = mask * data\n",
        "    data = data.to(device)\n",
        "    noisy_data = noisy_data.to(device)\n",
        "    noisy_data.requires_grad = False\n",
        "    data = data.view([-1, 784])\n",
        "    noisy_data = noisy_data.view([-1,784])\n",
        "    encoded_imgs = model.encoder(noisy_data)\n",
        "    decoded_imgs = model.decoder(encoded_imgs)\n",
        "    #\n",
        "    true_imgs = to_img(data)\n",
        "    noisy_imgs = to_img(noisy_data)\n",
        "    decoded_imgs = to_img(decoded_imgs)\n",
        "    encoded_imgs = encoded_imgs.cpu().data.numpy()\n",
        "\n",
        "    n = 10\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(4, n, i + 1)\n",
        "        plt.imshow(true_imgs[i])\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display corrupted original\n",
        "        ax = plt.subplot(4, n, i + 1 +n)\n",
        "        plt.imshow(noisy_imgs[i])\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display code\n",
        "        ax = plt.subplot(4, n, i + 1 + 2*n)\n",
        "        plt.imshow(encoded_imgs[i].reshape(-1,4))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(4, n, i + 1 +  3*n)\n",
        "        plt.imshow(decoded_imgs[i])\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFLDJ6f_2ujb"
      },
      "outputs": [],
      "source": [
        "plot_denoising(model, noise=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Optional: how to deal with convolutions?\n",
        "\n",
        "Hint: start by decreasing the size of your image with `Conv2d` by using a `stride` like:"
      ],
      "metadata": {
        "id": "L8aFFntJTn9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4qEpKsPPCY2"
      },
      "outputs": [],
      "source": [
        "conv = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1, stride=2)\n",
        "x = torch.randn(2, 8, 64, 64)\n",
        "y = conv(x)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggk9iuYMPCY2"
      },
      "source": [
        "Now use [transposed convolution](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html) (or [deconvolution](https://distill.pub/2016/deconv-checkerboard/)) with the same parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0eRt75APCY2"
      },
      "outputs": [],
      "source": [
        "convt = nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, stride=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxKylnA5PCY3"
      },
      "outputs": [],
      "source": [
        "convt(y).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QPUkHoPCY4"
      },
      "source": [
        "To get the same size as `x`, play with `output_padding`.\n",
        "\n",
        "Now, you have all the tools to build a convolutional autoencoder!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ApENOP0PCY6"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dldiy",
      "language": "python",
      "name": "dldiy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}